version: 2 # use CircleCI 2.0 instead of CircleCI Classic
jobs: # basic units of work in a run
  build: # runs not using Workflows must have a `build` job as entry point
    parallelism: 1 # run only one instance of this job in parallel
    docker: # run the steps with Docker
      - image: cimg/elixir:1.16.0-erlang-26.2.1
        environment: # environment variables for primary container
          MIX_ENV: test
          NODE_OPTIONS: --openssl-legacy-provider
          DISPLAY: :99
      - image: cimg/postgres:15.5-postgis # database image

    working_directory: ~/app # directory where steps will run

    steps: # commands that comprise the `build` job
      - checkout # check out source code to working directory

      - run: mix local.hex --force # install Hex locally (without prompt)
      - run: mix local.rebar --force # fetch a copy of rebar (without prompt)

      - run:
          name: Install System Dependencies
          command: |
            # Install dependencies
            sudo apt-get update
            sudo apt-get install -y curl inotify-tools firefox xvfb default-jre

            # Install Selenium Server
            SELENIUM_VERSION="3.141.59"
            wget https://selenium-release.storage.googleapis.com/3.141/selenium-server-standalone-$SELENIUM_VERSION.jar
            sudo mv selenium-server-standalone-$SELENIUM_VERSION.jar /usr/local/bin/selenium-server-standalone.jar
            sudo chmod +x /usr/local/bin/selenium-server-standalone.jar

            # Install geckodriver for Firefox
            GECKODRIVER_VERSION="v0.33.0"
            wget https://github.com/mozilla/geckodriver/releases/download/$GECKODRIVER_VERSION/geckodriver-$GECKODRIVER_VERSION-linux64.tar.gz
            sudo tar -xvf geckodriver-$GECKODRIVER_VERSION-linux64.tar.gz
            sudo mv geckodriver /usr/local/bin/
            sudo chmod +x /usr/local/bin/geckodriver
            rm geckodriver-$GECKODRIVER_VERSION-linux64.tar.gz

            # Set up Firefox for Wallaby
            echo "Setting up Firefox for Wallaby..."
            export FIREFOX_PATH=$(which firefox)
            echo "export FIREFOX_PATH=$FIREFOX_PATH" >> $BASH_ENV
            source $BASH_ENV
            echo "Firefox path: $FIREFOX_PATH"

            # Start Xvfb for headless browser testing
            Xvfb :99 -screen 0 1280x1024x24 > /dev/null 2>&1 &
            export DISPLAY=:99

            # Install Node.js and Yarn
            curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
            sudo apt-get install -y nodejs
            curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -
            echo "deb https://dl.yarnpkg.com/debian/ stable main" | sudo tee /etc/apt/sources.list.d/yarn.list
            sudo apt-get update
            sudo apt-get install -y yarn

            # Install dockerize
            DOCKERIZE_VERSION="v0.6.1"
            sudo wget https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            sudo tar -C /usr/local/bin -xzvf dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            sudo rm dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz

      - restore_cache: # restores saved mix cache
          keys: # list of cache keys, in decreasing specificity
            - v5-mix-cache-{{ .Branch }}-{{ checksum "mix.lock" }}
            - v5-mix-cache-{{ .Branch }}
            - v5-mix-cache
      - restore_cache: # restores saved build cache
          keys:
            - v5-build-cache-{{ .Branch }}
            - v5-build-cache
      - run: mix do deps.get, compile # get updated dependencies & compile them
      - restore_cache:
          name: Restore Yarn Package Cache
          keys:
            - v1-yarn-packages-{{ .Branch }}-{{ checksum "yarn.lock" }}
            - v1-yarn-packages-{{ .Branch }}
            - v1-yarn-packages-master
            - v1-yarn-packages-
      - run:
          name: Install Node Dependencies
          command: yarn install
      - save_cache:
          name: Save Yarn Package Cache
          key: v1-yarn-packages-{{ .Branch }}-{{ checksum "yarn.lock" }}
          paths:
            - node_modules/
      - save_cache: # generate and store cache so `restore_cache` works
          key: v5-mix-cache-{{ .Branch }}-{{ checksum "mix.lock" }}
          paths: 
            - deps
      - save_cache: # make another less specific cache
          key: v5-mix-cache-{{ .Branch }}
          paths:
            - deps
      - save_cache: # you should really save one more cache just in case
          key: v5-mix-cache
          paths:
            - deps
      - save_cache: # don't forget to save a *build* cache, too
          key: v5-build-cache-{{ .Branch }}
          paths:
            - _build
      - save_cache: # and one more build cache for good measure
          key: v5-build-cache
          paths:
            - _build

      - run: # special utility that stalls main process until DB is ready
          name: Wait for DB
          command: dockerize -wait tcp://localhost:5432 -timeout 1m

      - run:
          name: Check Database Configuration
          command: |
            # Just load and print config, no DB connection
            mix run --no-start -e "
              IO.puts(\"Loading configuration...\")
              Application.load(:remote_retro)
              config = Application.get_env(:remote_retro, RemoteRetro.Repo)
              IO.puts(\"Database config:\")
              config |> Enum.each(fn {k, v} -> 
                if is_binary(v), do: IO.puts(\"  #{k}: #{v}\")
              end)
            "

      - run:
          name: Create and Migrate Database
          command: |
            mix ecto.create
            mix ecto.migrate

      - run:
          name: Start Application
          command: |
            mix run -e "
              IO.puts(\"Starting application...\")
              {:ok, _} = Application.ensure_all_started(:remote_retro)
              repo_pid = Process.whereis(RemoteRetro.Repo)
              IO.puts(\"Repo process: #{inspect(repo_pid)}\")
            "

      - run:
          name: Start and Verify Selenium
          command: |
            # Start Selenium with logging
            java -jar /usr/local/bin/selenium-server-standalone.jar -port 4444 > selenium.log 2>&1 &
            
            # Wait for Selenium and verify connection
            for i in {1..30}; do
              if curl -s http://localhost:4444/wd/hub/status > /dev/null; then
                echo "Selenium is up and running"
                break
              fi
              echo "Waiting for Selenium... attempt $i/30"
              sleep 2
            done
            
            # Verify Firefox and geckodriver
            echo "Firefox version: $(firefox --version)"
            echo "Geckodriver version: $(geckodriver --version)"
            
            # Test Selenium connection
            curl -s http://localhost:4444/wd/hub/status | grep "ready"

      - run: yarn test # run all js tests in project
      - run: yarn run compile-test
      - run:
          command: |
            if [ "$COVERALLS_REPO_TOKEN" != "" ]; then
              mix coveralls.circle --include feature_test;
            else
              mix test --exclude feature_test;
              mix test --only feature_test;
            fi

      - store_test_results: # upload test results for display in Test Summary
          path: _build/test/junit
      - store_artifacts:
          path: screenshots
      - store_artifacts:
          path: selenium.log
      - store_artifacts:
          path: browser_logs.log

  deploy:
    machine: true
    working_directory: ~/app # directory where steps will run
    steps:
      - checkout
      - run:
          name: Deploy to Gigalixir
          command: |
            git remote add gigalixir https://$GIGALIXIR_EMAIL:$GIGALIXIR_API_KEY@git.gigalixir.com/$GIGALIXIR_APP_NAME.git
            commit_range_from_previous_build=$(echo $CIRCLE_COMPARE_URL | sed -n -e 's/^.*compare\///p')

            # trigger full rebuilds when elixir deps or prod environment configs have changed
            #   - also trigger full rebuilds when db migrations have been *added* since last push,
            #     as these wouldn't be run when doing a hot upgrade, but are run on fresh builds

            if git log $commit_range_from_previous_build --name-status --pretty="format:" | grep "phoenix_static_buildpack.config\config.exs\|prod.exs\|mix.exs\|mix.lock\|elixir_buildpack.config\|A[[:space:]]priv/repo/migrations"; then
              echo "Executing deploy cleaned of old dependencies"
              git -c http.extraheader="GIGALIXIR-CLEAN: true" push gigalixir HEAD:refs/heads/master --force;
            else
              echo "Executing deploy with hot code upgrade"
              git -c http.extraheader="GIGALIXIR-HOT: true" push gigalixir HEAD:refs/heads/master --force;
            fi

      - run:
          name: Notify HoneyBadger of Deploy
          command: |
            curl --data "deploy[environment]=production&deploy[revision]=$CIRCLE_SHA1&deploy[repository]=https://github.com/stride-nyc/remote_retro&api_key=$HONEYBADGER_API_KEY" "https://api.honeybadger.io/v1/deploys"

workflows:
  version: 2
  build-and-deploy:
    jobs:
      - build
      - deploy:
          requires:
            - build
          filters:
            branches:
              only: master
