version: 2 # use CircleCI 2.0 instead of CircleCI Classic
jobs: # basic units of work in a run
  build: # runs not using Workflows must have a `build` job as entry point
    parallelism: 1 # run only one instance of this job in parallel
    docker: # run the steps with Docker
      - image: cimg/elixir:1.16.0-erlang-26.2.1
        environment: # environment variables for primary container
          MIX_ENV: test
          NODE_OPTIONS: --openssl-legacy-provider
          DISPLAY: :99
      - image: cimg/postgres:15.5-postgis # database image

    working_directory: ~/app # directory where steps will run

    steps: # commands that comprise the `build` job
      - checkout # check out source code to working directory

      - run: mix local.hex --force # install Hex locally (without prompt)
      - run: mix local.rebar --force # fetch a copy of rebar (without prompt)

      - run:
          name: Install System Dependencies
          command: |
            # Install dependencies
            sudo apt-get update
            sudo apt-get install -y curl inotify-tools firefox xvfb default-jre

            # Install Selenium Server
            SELENIUM_VERSION="3.141.59"
            wget https://selenium-release.storage.googleapis.com/3.141/selenium-server-standalone-$SELENIUM_VERSION.jar
            sudo mv selenium-server-standalone-$SELENIUM_VERSION.jar /usr/local/bin/selenium-server-standalone.jar
            sudo chmod +x /usr/local/bin/selenium-server-standalone.jar

            # Install geckodriver for Firefox
            GECKODRIVER_VERSION="v0.33.0"
            wget https://github.com/mozilla/geckodriver/releases/download/$GECKODRIVER_VERSION/geckodriver-$GECKODRIVER_VERSION-linux64.tar.gz
            sudo tar -xvf geckodriver-$GECKODRIVER_VERSION-linux64.tar.gz
            sudo mv geckodriver /usr/local/bin/
            sudo chmod +x /usr/local/bin/geckodriver
            rm geckodriver-$GECKODRIVER_VERSION-linux64.tar.gz

            # Set up Firefox for Wallaby
            echo "Setting up Firefox for Wallaby..."
            export FIREFOX_PATH=$(which firefox)
            echo "export FIREFOX_PATH=$FIREFOX_PATH" >> $BASH_ENV
            source $BASH_ENV
            echo "Firefox path: $FIREFOX_PATH"

            # Start Xvfb for headless browser testing
            Xvfb :99 -screen 0 1280x1024x24 > /dev/null 2>&1 &
            export DISPLAY=:99

            # Install Node.js and Yarn
            curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
            sudo apt-get install -y nodejs
            curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -
            echo "deb https://dl.yarnpkg.com/debian/ stable main" | sudo tee /etc/apt/sources.list.d/yarn.list
            sudo apt-get update
            sudo apt-get install -y yarn

            # Install dockerize
            DOCKERIZE_VERSION="v0.6.1"
            sudo wget https://github.com/jwilder/dockerize/releases/download/$DOCKERIZE_VERSION/dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            sudo tar -C /usr/local/bin -xzvf dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz
            sudo rm dockerize-linux-amd64-$DOCKERIZE_VERSION.tar.gz

      - restore_cache: # restores saved mix cache
          keys: # list of cache keys, in decreasing specificity
            - v5-mix-cache-{{ .Branch }}-{{ checksum "mix.lock" }}
            - v5-mix-cache-{{ .Branch }}
            - v5-mix-cache
      - restore_cache: # restores saved build cache
          keys:
            - v5-build-cache-{{ .Branch }}
            - v5-build-cache
      - run: mix do deps.get, compile # get updated dependencies & compile them
      - restore_cache:
          name: Restore Yarn Package Cache
          keys:
            - v1-yarn-packages-{{ .Branch }}-{{ checksum "yarn.lock" }}
            - v1-yarn-packages-{{ .Branch }}
            - v1-yarn-packages-master
            - v1-yarn-packages-
      - run:
          name: Install Node Dependencies
          command: yarn install
      - save_cache:
          name: Save Yarn Package Cache
          key: v1-yarn-packages-{{ .Branch }}-{{ checksum "yarn.lock" }}
          paths:
            - node_modules/
      - save_cache: # generate and store cache so `restore_cache` works
          key: v5-mix-cache-{{ .Branch }}-{{ checksum "mix.lock" }}
          paths: 
            - deps
      - save_cache: # make another less specific cache
          key: v5-mix-cache-{{ .Branch }}
          paths:
            - deps
      - save_cache: # you should really save one more cache just in case
          key: v5-mix-cache
          paths:
            - deps
      - save_cache: # don't forget to save a *build* cache, too
          key: v5-build-cache-{{ .Branch }}
          paths:
            - _build
      - save_cache: # and one more build cache for good measure
          key: v5-build-cache
          paths:
            - _build

      - run:
          name: Setup Database
          command: |
            # Wait for Postgres to be ready
            dockerize -wait tcp://localhost:5432 -timeout 1m

            # Create test database with manual commands first
            PGPASSWORD=postgres psql -h localhost -U postgres -c 'CREATE DATABASE remote_retro_test;'
            
            # Configure optimized database settings
            mix run -e '
              Application.put_env(:remote_retro, RemoteRetro.Repo,
                pool_size: 20,
                queue_target: 5000,
                queue_interval: 10000
              )
            '
            
            # Now run Ecto commands
            mix ecto.create --quiet || true  # The || true prevents failure if DB exists
            mix ecto.migrate --quiet

      - run:
          name: Verify Database Setup
          command: |
            # First, let's verify PostgreSQL is accepting connections
            echo "Verifying PostgreSQL connection..."
            max_attempts=5
            counter=1
            until PGPASSWORD=postgres psql -h localhost -U postgres -c '\l' > /dev/null 2>&1; do
              if [ $counter -eq $max_attempts ]; then
                echo "Failed to connect to PostgreSQL after $max_attempts attempts"
                exit 1
              fi
              echo "Attempt $counter of $max_attempts - Waiting for PostgreSQL..."
              sleep 3
              ((counter++))
            done
            echo "✓ PostgreSQL is accepting connections"

            # Now verify our specific database exists and is accessible
            echo "\nVerifying test database..."
            if PGPASSWORD=postgres psql -h localhost -U postgres -lqt | cut -d \| -f 1 | grep -qw remote_retro_test; then
              echo "✓ Database 'remote_retro_test' exists"
              
              # Verify we can connect to the specific database
              if PGPASSWORD=postgres psql -h localhost -U postgres -d remote_retro_test -c 'SELECT current_timestamp;' > /dev/null 2>&1; then
                echo "✓ Can connect to 'remote_retro_test' database"
                
                # Check if our migrations table exists
                if PGPASSWORD=postgres psql -h localhost -U postgres -d remote_retro_test -c '\dt schema_migrations' | grep -q schema_migrations; then
                  echo "✓ Migrations table exists"
                  
                  # Get the current migration version
                  current_version=$(PGPASSWORD=postgres psql -h localhost -U postgres -d remote_retro_test -t -c 'SELECT version FROM schema_migrations ORDER BY version DESC LIMIT 1;')
                  echo "✓ Current migration version: $current_version"
                else
                  echo "✗ Migrations table not found - running migrations..."
                  mix ecto.migrate
                fi
              else
                echo "✗ Cannot connect to 'remote_retro_test' database"
                exit 1
              fi
            else
              echo "✗ Database 'remote_retro_test' does not exist"
              exit 1
            fi

            # Verify database configuration matches our expectations
            mix run -e '
              db_config = Application.get_env(:remote_retro, RemoteRetro.Repo)
              expected_config = [
                hostname: "localhost",
                database: "remote_retro_test",
                username: "postgres",
                password: "postgres"
              ]
              
              Enum.each(expected_config, fn {key, expected_value} ->
                actual_value = db_config[key]
                if actual_value == expected_value do
                  IO.puts "✓ #{key}: #{actual_value}"
                else
                  IO.puts "✗ #{key} mismatch - expected: #{expected_value}, got: #{actual_value}"
                  System.halt(1)
                end
              end)
            '

      - run:
          name: Setup Test Environment
          command: |
            mix run -e '
              # First, let''s ensure our configuration is loaded properly
              IO.puts "Loading configuration..."
              Application.load(:remote_retro)
              
              # Let''s verify our database configuration
              db_config = Application.get_env(:remote_retro, RemoteRetro.Repo)
              IO.puts """
              Database configuration:
              - Hostname: #{db_config[:hostname]}
              - Database: #{db_config[:database]}
              - Username: #{db_config[:username]}
              - Pool Size: #{db_config[:pool_size]}
              """
              
              # Start our dependencies in the correct order
              IO.puts "\nStarting core dependencies..."
              {:ok, _} = Application.ensure_all_started(:logger)
              {:ok, _} = Application.ensure_all_started(:ssl)
              {:ok, _} = Application.ensure_all_started(:postgrex)
              
              # Start Ecto separately to better track any issues
              IO.puts "\nStarting Ecto..."
              {:ok, _} = Application.ensure_all_started(:ecto_sql)
              
              # Now start our application
              IO.puts "\nStarting RemoteRetro..."
              case Application.ensure_all_started(:remote_retro) do
                {:ok, started_apps} ->
                  IO.puts "Started applications: #{inspect(started_apps)}"
                {:error, {app, reason}} ->
                  IO.puts "Failed to start #{app}: #{inspect(reason)}"
                  System.halt(1)
              end
              
              # Important: Configure sandbox BEFORE trying to use the connection
              IO.puts "\nSetting up database sandbox..."
              :ok = Ecto.Adapters.SQL.Sandbox.mode(RemoteRetro.Repo, :manual)
              
              # Now check out a connection for this process
              :ok = Ecto.Adapters.SQL.Sandbox.checkout(RemoteRetro.Repo)
              
              # Make it shared so child processes can use it
              Ecto.Adapters.SQL.Sandbox.mode(RemoteRetro.Repo, {:shared, self()})
              
              # Add robust connection verification with detailed logging
              IO.puts "\nVerifying database connection..."
              max_attempts = 3
              
              result = Enum.reduce_while(1..max_attempts, {:error, nil}, fn attempt, _ ->
                IO.puts "\nAttempt #{attempt} of #{max_attempts}"
                :timer.sleep(2000)
                
                try do
                  case RemoteRetro.Repo.query("SELECT current_timestamp") do
                    {:ok, result} ->
                      timestamp = result.rows |> List.first() |> List.first()
                      IO.puts "✓ Database connection successful - Server time: #{timestamp}"
                      {:halt, {:ok, result}}
                    {:error, error} ->
                      IO.puts "✗ Query failed: #{inspect(error)}"
                      if attempt == max_attempts, do: {:halt, {:error, error}}, else: {:cont, {:error, error}}
                  end
                rescue
                  e in DBConnection.ConnectionError ->
                    IO.puts "✗ Connection error: #{Exception.message(e)}"
                    if attempt == max_attempts, do: {:halt, {:error, e}}, else: {:cont, {:error, e}}
                  e ->
                    IO.puts "✗ Unexpected error: #{inspect(e)}"
                    if attempt == max_attempts, do: {:halt, {:error, e}}, else: {:cont, {:error, e}}
                end
              end)

              case result do
                {:ok, _} -> 
                  IO.puts "\n✓ Database setup completed successfully"
                  # Proper cleanup
                  Ecto.Adapters.SQL.Sandbox.checkin(RemoteRetro.Repo)
                {:error, error} -> 
                  IO.puts "\n✗ Database setup failed: #{inspect(error)}"
                  # Ensure we clean up even on failure
                  Ecto.Adapters.SQL.Sandbox.checkin(RemoteRetro.Repo)
                  System.halt(1)
              end

              # Register cleanup on exit
              :ok = ExUnit.after_suite(fn ->
                IO.puts "\nCleaning up test environment..."
                :ok = Application.stop(:remote_retro)
                :ok = Application.stop(:wallaby)
                :ok = Application.stop(:phoenix)
              end)
            '

      - run:
          name: Setup Selenium
          command: |
            # Start Xvfb first
            Xvfb :99 -screen 0 1280x1024x24 &
            export DISPLAY=:99
            
            # Start Selenium with detailed logging
            java -Dwebdriver.gecko.driver=/usr/local/bin/geckodriver \
                 -Dwebdriver.firefox.logfile=firefox.log \
                 -jar /usr/local/bin/selenium-server-standalone.jar \
                 -port 4444 \
                 -log selenium-debug.log &
            
            # Wait for Selenium with better error handling
            max_attempts=45
            attempt=1
            echo "Waiting for Selenium..."
            while ! curl -s http://localhost:4444/wd/hub/status > /dev/null; do
              if [ $attempt -eq $max_attempts ]; then
                echo "Selenium failed to start after $max_attempts attempts"
                echo "=== Selenium Logs ==="
                cat selenium-debug.log
                echo "=== Firefox Logs ==="
                cat firefox.log
                exit 1
              fi
              echo "Attempt $attempt/$max_attempts..."
              sleep 2
              attempt=$((attempt + 1))
            done
            
            echo "Selenium is running"
            curl -s http://localhost:4444/wd/hub/status

      - run: yarn test # run all js tests in project
      - run: yarn run compile-test
      - run:
          name: Run Tests
          command: |
            # Setup test environment with proper connection management
            mix run -e '
              # First load all necessary applications
              IO.puts "Loading applications..."
              Application.load(:remote_retro)
              {:ok, _} = Application.ensure_all_started(:remote_retro)
              
              # Configure sandbox mode for testing
              IO.puts "Configuring database sandbox..."
              :ok = Ecto.Adapters.SQL.Sandbox.mode(RemoteRetro.Repo, :manual)
              
              # Explicitly check out a connection for this process
              IO.puts "Checking out database connection..."
              :ok = Ecto.Adapters.SQL.Sandbox.checkout(RemoteRetro.Repo)
              
              # Allow other processes to share this connection
              Ecto.Adapters.SQL.Sandbox.mode(RemoteRetro.Repo, {:shared, self()})
              
              # Now verify database is ready
              IO.puts "Verifying database connection..."
              try do
                case RemoteRetro.Repo.query("SELECT 1") do
                  {:ok, _} -> 
                    IO.puts "✓ Database ready for testing"
                  {:error, error} -> 
                    IO.puts "✗ Database error: #{inspect(error)}"
                    System.halt(1)
                end
              after
                # Always check the connection back in
                Ecto.Adapters.SQL.Sandbox.checkin(RemoteRetro.Repo)
              end
            '
            
            echo "Running non-feature tests..."
            if ! mix test --exclude feature_test --trace; then
              echo "Non-feature tests failed"
              exit 1
            fi
            
            echo "Running feature tests..."
            if ! MIX_ENV=test TEST_DEBUG=1 mix test --only feature_test --trace; then
              echo "Feature tests failed"
              exit 1
            fi
            
            # Run coverage if token is available
            if [ "$COVERALLS_REPO_TOKEN" != "" ]; then
              echo "Running coverage report..."
              mix coveralls.circle --include feature_test
            fi

      - store_test_results: # upload test results for display in Test Summary
          path: _build/test/junit
      - store_artifacts:
          path: screenshots
      - store_artifacts:
          path: selenium-debug.log
      - store_artifacts:
          path: firefox.log
      - store_artifacts:
          path: browser_logs.log

  deploy:
    machine: true
    working_directory: ~/app # directory where steps will run
    steps:
      - checkout
      - run:
          name: Deploy to Gigalixir
          command: |
            git remote add gigalixir https://$GIGALIXIR_EMAIL:$GIGALIXIR_API_KEY@git.gigalixir.com/$GIGALIXIR_APP_NAME.git
            commit_range_from_previous_build=$(echo $CIRCLE_COMPARE_URL | sed -n -e 's/^.*compare\///p')

            # trigger full rebuilds when elixir deps or prod environment configs have changed
            #   - also trigger full rebuilds when db migrations have been *added* since last push,
            #     as these wouldn't be run when doing a hot upgrade, but are run on fresh builds

            if git log $commit_range_from_previous_build --name-status --pretty="format:" | grep "phoenix_static_buildpack.config\config.exs\|prod.exs\|mix.exs\|mix.lock\|elixir_buildpack.config\|A[[:space:]]priv/repo/migrations"; then
              echo "Executing deploy cleaned of old dependencies"
              git -c http.extraheader="GIGALIXIR-CLEAN: true" push gigalixir HEAD:refs/heads/master --force;
            else
              echo "Executing deploy with hot code upgrade"
              git -c http.extraheader="GIGALIXIR-HOT: true" push gigalixir HEAD:refs/heads/master --force;
            fi

      - run:
          name: Notify HoneyBadger of Deploy
          command: |
            curl --data "deploy[environment]=production&deploy[revision]=$CIRCLE_SHA1&deploy[repository]=https://github.com/stride-nyc/remote_retro&api_key=$HONEYBADGER_API_KEY" "https://api.honeybadger.io/v1/deploys"

workflows:
  version: 2
  build-and-deploy:
    jobs:
      - build
      - deploy:
          requires:
            - build
          filters:
            branches:
              only: master
